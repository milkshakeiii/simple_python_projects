I did three test runs, and cProfile put client.py's runtime at 60.986s, 36.350s, and 34.418s.

However, I am experiencing performance problems where sometimes the communication between the client and server slows to a crawl.  For example, a run after my test runs took 228.917s.  Sometimes it is much slower even than that.  Also, after code cleanup, I am experience the slowdown even more often.  I have not fully diagnosed the problem.  The server seems to block on select.select, a method which seems important for socket programming but which I am not very familiar with.  The same slowdown occurs when I limit the client to only storing 20 requests in memory at a time, which means that I did not fulfill the given requirement for only "up to 20 DIRLIST
commands [to] be in the pipeline to the server." (Quote from the challenge doc.)

My implementation's memory complexity is linear in the number of directories in the simulated directory structure.  This translates to only 119 bytes but the memory complexity would be constant if I had successfully implemented the limit of 20 pending requests.









Depth first search would not be a good choice for this situation because it would require the client to query the server, wait for a list of directories, and then choose the first directory and query the server again, and wait again, and so on.  When the client gets a list of directories, it knows it needs to send requests for each of those directories, and should therefore send them in batches rather than waiting for network delay for every one of them.

My approach is a bredth first search where the client queues up requests for every directory as it receives them.  This should be significantly more performant over a network.  However, my approach has a flaw in that I queue up too many requests at a time, using a large amount of memory.